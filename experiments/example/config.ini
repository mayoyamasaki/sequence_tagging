[path]
output_path=experiments/example/results/
model_output=${output_path}model.weights/
log_path=${output_path}log.txt

[data]
# embeddings
dim=50
dim_char=15
glove_filename=data/glove.6B/sampled-glove.6B.${dim}d.txt
# trimmed embeddings (created from glove_filename with build_data.py)
trimmed_filename=data/glove.6B.${dim}d.trimmed.npz

dev_filename=data/devel.iob
test_filename=data/test.iob
train_filename=data/train.iob
# if not None, max number of examples
max_iter=None

# vocab (created from dataset with build_data.py)
words_filename=data/words.txt
tags_filename=data/tags.txt
chars_filename=data/chars.txt

[hyperparameters]
# training
train_embeddings=False
nepochs=15
dropout=0.5
batch_size=20
lr= 0.001
lr_decay= 0.9
nepoch_no_imprv= 3

# model hyperparameters
hidden_size=300
char_hidden_size=100

# NOTE: if both chars and crf, only 1.6x slower on GPU
# if crf, training is 1.7x slower on CPU
crf=True
# if char embedding, training is 3.5x slower on CPU
chars=True
